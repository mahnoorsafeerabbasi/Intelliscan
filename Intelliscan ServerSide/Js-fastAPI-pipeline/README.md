# AI vs AI Code Detection: LLM vs LLM Experiment

## Overview

This project is an **experimental solution** to detect AI-written code by comparing it against human-written code using the concept of **LLM vs LLM** (Large Language Model vs Large Language Model). The primary goal of this tool is to identify whether code snippets are written by humans or generated by AI systems. The target audience for this project is **students in their early semesters** who are being introduced to programming. The tool aims to **promote academic integrity**, ensuring that students learn coding concepts and develop their own skills without relying on AI-generated code.

This tool uses a combination of advanced **Language Models (LM)** to analyze and assess code snippets in multiple languages, with a focus on **AI vs AI** detection. Currently, this system works best for **short code snippets** but has potential for further development as more powerful models (like OpenAI's GPT-3 or GPT-4) are integrated.

## Why this Experiment?

The idea behind this experiment is to challenge the conventional methods of detecting AI-written code by utilizing a different approach: **using AI models to detect other AI models' outputs**. This **LLM vs LLM** concept is novel and innovative because it opens up the possibility for more nuanced detection strategies. 

While the current model is not perfect, it presents an interesting first step towards better understanding how to distinguish between human and AI-generated code. We believe this approach can be extended to many other areas in the future, such as detecting AI-generated content in essays, art, or other creative works.

## Current Use Case

- **Target Audience**: Students (especially those in their early semesters) to ensure academic integrity and improve learning outcomes.
- **Purpose**: Detect AI-generated code and prevent its use in academic assignments.
- **Languages Supported**: Currently, the system works with short code snippets in the following languages:
  - **Python**
  - **C++**
  - **Java**
  - **JavaScript**

The system compares code snippets to check for common AI traits and then provides a detailed breakdown of whether the code is more likely human-written or AI-generated.

## How It Works

### 1. **Preprocessing**:
   The provided code is first cleaned to remove comments and unnecessary whitespaces. This helps in focusing purely on the logic of the code, making it easier to analyze and compare.

### 2. **Vectorization**:
   The code snippets are converted into vectors using **BERT (Bidirectional Encoder Representations from Transformers)**, a transformer model that is primarily used for natural language processing tasks. These vectors represent the semantics of the code and are used to measure similarity between different code snippets.

### 3. **Pinecone Index**:
   The vectorized code is then stored in an external index (Pinecone), where it can be queried for similarity to other code snippets. Pinecone is a vector database that helps store and search for code vectors efficiently.

### 4. **Model Analysis**:
   - **Google Gemini** is used to analyze code and provide an AI vs Human percentage. This gives an estimate of how much of the code is likely AI-generated.
   - **Gemini** performs a detailed analysis of the code snippet, considering factors like complexity, verbosity, and lack of comments, all of which are indicators of AI-generated code.

### 5. **Output**:
   The system outputs a report with:
   - **AI-generated percentage**
   - **Human-generated percentage**
   - **Detailed feedback on syntax issues, error handling**, and general characteristics of the code.
   
### 6. **Final Verdict**:
   The AI model generates a final analysis, including:
   - Assessment of the overall code quality
   - Explanation of how the code might differ from human-written code
   - A breakdown of how the AI vs human percentages were calculated

## Features

### **Pros**:
1. **Detailed Feedback**: The tool provides detailed feedback on code quality, including suggestions for improvement, error handling, and more.
2. **AI vs Human Detection**: By utilizing the **LLM vs LLM** concept, the system is capable of intelligently determining whether the code was written by an AI or a human.
3. **Short Code Snippets**: Works well with smaller, concise code snippets, which is often the case in early semester programming assignments.
4. **Innovative**: The LLM vs LLM approach is completely new and innovative, offering new ways to analyze code.
5. **Potential for Other Use Cases**: This method can be applied to detect AI-generated content in many other fields, such as essays, emails, or even creative writing.
   
   **Other potential uses**:
   - **AI vs Human Essay Detection**: In educational settings, this can be used to distinguish between AI-generated and human-written essays.
   - **Content Creation**: Detecting AI-generated articles, blog posts, or social media content.
   - **Art and Creativity**: Identifying AI-generated art or design patterns.

### **Cons**:
1. **Limited by Model Capabilities**: The current model (BERT) is not generative and may not always capture subtle nuances in code. For better performance, more advanced models like **GPT-4** can be used.
2. **Works Best on Short Snippets**: This approach works best for small code snippets but struggles with large, complex codebases.
3. **Experimental Nature**: While promising, this method is still in the experimental stage, and improvements will be needed to make it more accurate and robust.

## Setup and Installation

### Prerequisites:
- Python 3.x
- An IDE or text editor (like VSCode or PyCharm)
- clone the repo
- intall reuirements
-run fast-API


